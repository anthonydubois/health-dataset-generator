{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.master" : "local[*]"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# Manipulating the Concept table\n",
        "\n",
        "\n",
        "This small notebook shows how to manipulate the Concept table.\n",
        "\n",
        "\n",
        "It is also an introduction to Polynote notebooks and Spark on Scala.\n",
        "\n",
        "This notebook requires the Docker image to be run with the concept table, in parquet format, mounted toÂ \"/opt/refs/concept.parquet\".\n",
        "\n",
        ">"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920517752,
          "endTs" : 1585920536535
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Read the concept table\n",
        "val df = spark.read.parquet(\"/opt/refs/concept.parquet\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920539481,
          "endTs" : 1585920570481
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Select distinct standard concepts\n",
        "import spark.implicits._\n",
        "df.groupBy('standard_concept).count().show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+----------------+-------+\n",
            "|standard_concept|  count|\n",
            "+----------------+-------+\n",
            "|               F|     31|\n",
            "|            null|3010766|\n",
            "|               C| 362142|\n",
            "|               S|2551449|\n",
            "+----------------+-------+\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920573277,
          "endTs" : 1585920575673
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Register the dataframe as a temp view. This way, it becomes\n",
        "// queriable through SQL.\n",
        "df.createOrReplaceTempView(\"concept\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920578301,
          "endTs" : 1585920591187
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Same query as above (select distinct) but in SQL.\n",
        "spark.sql(\"\"\"\n",
        "    select\n",
        "        standard_concept,\n",
        "        count(*) as count\n",
        "    from concept\n",
        "    group by standard_concept\n",
        "\"\"\").show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+----------------+-------+\n",
            "|standard_concept|  count|\n",
            "+----------------+-------+\n",
            "|               F|     31|\n",
            "|            null|3010766|\n",
            "|               C| 362142|\n",
            "|               S|2551449|\n",
            "+----------------+-------+\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920594237,
          "endTs" : 1585920596649
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Notice that everything is lazily evaluated in Spark. Therefore,\n",
        "// in the following query, only the first 10 rows are actually fetched,\n",
        "// even though there is no \"limit 10\" in the query.\n",
        "spark.sql(\"select concept_code from concept\").show(10)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------+\n",
            "|concept_code|\n",
            "+------------+\n",
            "|      RAC100|\n",
            "|           a|\n",
            "|       ug/kg|\n",
            "|     M1A.352|\n",
            "|  D000069036|\n",
            "|     R40.211|\n",
            "|     S00.411|\n",
            "|      S05.70|\n",
            "|       S07.1|\n",
            "|      S36.39|\n",
            "+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920599036,
          "endTs" : 1585920600968
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// The columns are\n",
        "df.columns.mkString(\", \")"
      ],
      "outputs" : [
        {
          "execution_count" : 6,
          "data" : {
            "text/plain" : [
              "key, hash, insert_datetime, update_datetime, delete_datetime, change_datetime, concept_id, concept_name, domain_id, vocabulary_id, concept_class_id, standard_concept, concept_code, valid_start_date, valid_end_date, invalid_reason, m_language_id, m_projec"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "String"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1585920604047,
          "endTs" : 1585920605430
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// The schema is\n",
        "println(df.schema)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "StructType(StructField(key,StringType,true), StructField(hash,StringType,true), StructField(insert_datetime,StringType,true), StructField(update_datetime,StringType,true), StructField(delete_datetime,StringType,true), StructField(change_datetime,StringType,true), StructField(concept_id,StringType,true), StructField(concept_name,StringType,true), StructField(domain_id,StringType,true), StructField(vocabulary_id,StringType,true), StructField(concept_class_id,StringType,true), StructField(standard_concept,StringType,true), StructField(concept_code,StringType,true), StructField(valid_start_date,StringType,true), StructField(valid_end_date,StringType,true), StructField(invalid_reason,StringType,true), StructField(m_language_id,StringType,true), StructField(m_project_id,StringType,true), StructField(row_id,StringType,true))\n"
          ],
          "output_type" : "stream"
        }
      ]
    }
  ]
}